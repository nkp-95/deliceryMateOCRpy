import cv2
import numpy as np
import pytesseract
from paddleocr import PaddleOCR

def show_image(title, image):
    """ë””ë²„ê¹…ìš© ì´ë¯¸ì§€ ì¶œë ¥ í•¨ìˆ˜"""
    cv2.imshow(title, image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def preprocess_image(image_path):
  """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: í‘ë°± ë³€í™˜, ëŒ€ë¹„ ì¡°ì •, ë…¸ì´ì¦ˆ ì œê±° ë“±"""
  
  # ì›ë³¸ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
  image = cv2.imread(image_path)
  show_image("Original Image", image)

  # 1. **í‘ë°± ë³€í™˜**
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  show_image("Grayscale Image", gray)

  # 2. **ë°ê¸° ë³´ì • ë° ëŒ€ë¹„ ê°•í™”**
  equalized = cv2.equalizeHist(gray)
  show_image("Histogram Equalized", equalized)

  # 3. **Adaptive Thresholding ì ìš©** (ë¡œì»¬ ëŒ€ë¹„ ìµœì í™”)
  adaptive_thresh = cv2.adaptiveThreshold(equalized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                          cv2.THRESH_BINARY, 11, 2)
  show_image("Adaptive Thresholding", adaptive_thresh)

  # 4. **Sharpening (ì„ ëª…í™”) ì ìš©**
  kernel = np.array([[0, -1, 0],
                      [-1,  5, -1],
                      [0, -1, 0]])
  sharpened = cv2.filter2D(adaptive_thresh, -1, kernel)
  show_image("Sharpened Image", sharpened)

  # 5. **ì—£ì§€ ê²€ì¶œ (Canny)**
  edged = cv2.Canny(sharpened, 50, 200)
  show_image("Edge Detection (Canny)", edged)

  return image, edged

def detect_text_box(image, edged):
  """ì‚¬ê°í˜• ë°•ìŠ¤ ê²€ì¶œí•˜ì—¬ OCR ì˜ì—­ í¬ë¡­"""
  
  contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  best_box = None
  max_area = 0

  for cnt in contours:
    approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
    if len(approx) == 4:
      x, y, w, h = cv2.boundingRect(approx)
      aspect_ratio = w / float(h)

      # íŠ¹ì • ë¹„ìœ¨ê³¼ í¬ê¸°ë¥¼ ë§Œì¡±í•˜ëŠ” ê²½ìš° ì„ íƒ
      if 1.5 < aspect_ratio < 3 and w * h > 5000:  
        if w * h > max_area:
          best_box = (x, y, w, h)
          max_area = w * h

  if best_box:
    x, y, w, h = best_box
    cropped = image[y:y+h, x:x+w]
    show_image("Cropped ROI", cropped)
    cv2.imwrite("cropped_output.jpg", cropped)
    print("âœ… [INFO] í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_output.jpg")
    return cropped
  else:
    print("âš ï¸ [ERROR] í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return None

def extract_text_from_image(image):
  """OCR ì‹¤í–‰"""
  
  config = "--oem 3 --psm 6"
  text_tesseract = pytesseract.image_to_string(image, config=config, lang='kor+eng')

  # PaddleOCR í•œê¸€ & ì˜ì–´ OCR ë”°ë¡œ ìˆ˜í–‰
  ocr_korean = PaddleOCR(lang="korean")
  result_korean = ocr_korean.ocr(image, cls=True)

  ocr_english = PaddleOCR(lang="en")
  result_english = ocr_english.ocr(image, cls=True)

  # OCR ê²°ê³¼ ì˜ˆì™¸ ì²˜ë¦¬
  def extract_text(result):
    return " ".join([word[1][0] for line in result if line for word in line]) if result and result != [[]] else ""

  text_paddle_korean = extract_text(result_korean)
  text_paddle_english = extract_text(result_english)

  # ë‘ OCR ê²°ê³¼ í•©ì¹˜ê¸°
  return text_tesseract.strip() + " " + text_paddle_korean.strip() + " " + text_paddle_english.strip()


def main(image_path):
  print("ğŸ” [INFO] íŠ¹ì • ìœ„ì¹˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

  image, edged = preprocess_image(image_path)

  cropped_image = detect_text_box(image, edged)
  if cropped_image is None:
    return None

  # í¬ë¡­ëœ ì´ë¯¸ì§€ í•´ìƒë„ ì¦ê°€ í›„ OCR ì‹¤í–‰
  resized = cv2.resize(cropped_image, (cropped_image.shape[1] * 2, cropped_image.shape[0] * 2))
  show_image("Resized Image for OCR", resized)

  print("âœ… [INFO] í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ë¡­ ì„±ê³µ. OCR ì ìš© ì¤‘...")
  text_result = extract_text_from_image(resized)

  print("\nâœ… [FINAL RESULT]")
  print(text_result)

if __name__ == "__main__":
  image_path = "C:\\DB\\images\\KakaoTalk_20220829_090207582_01.jpg"
  main(image_path)
