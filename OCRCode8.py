import cv2
import numpy as np
import pytesseract
from paddleocr import PaddleOCR

def show_image(title, image):
    """ë””ë²„ê¹…ìš© ì´ë¯¸ì§€ ì¶œë ¥ í•¨ìˆ˜"""
    if image is None:
        print(f"âš ï¸ [ERROR] '{title}' ì´ë¯¸ì§€ê°€ Noneì…ë‹ˆë‹¤. ì¶œë ¥ ë¶ˆê°€.")
        return
    resized_image = cv2.resize(image, (600, 400))
    cv2.imshow(title, resized_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: í‘ë°± ë³€í™˜, ëŒ€ë¹„ ì¡°ì •, ë…¸ì´ì¦ˆ ì œê±° ë“±"""
    image = cv2.imread(image_path)

    if image is None:
        print("âš ï¸ [ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
        return None, None

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)
    adaptive_thresh = cv2.adaptiveThreshold(equalized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    edged = cv2.Canny(adaptive_thresh, 50, 200)

    return image, edged

def detect_text_box(image, edged):
    """ì‚¬ê°í˜• ë°•ìŠ¤ ê²€ì¶œí•˜ì—¬ OCR ì˜ì—­ í¬ë¡­"""
    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    best_box = None
    max_area = 0

    for cnt in contours:
        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
        if len(approx) == 4:
            x, y, w, h = cv2.boundingRect(approx)
            aspect_ratio = w / float(h)

            if 1.5 < aspect_ratio < 3 and w * h > 5000:  
                if w * h > max_area:
                    best_box = (x, y, w, h)
                    max_area = w * h

    if best_box:
        x, y, w, h = best_box
        y = max(0, y - int(h * 0.3))
        cropped = image[y:y+h, x:x+w]
        show_image("Cropped ROI", cropped)
        return cropped
    else:
        print("âš ï¸ [ERROR] í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

def extract_text_from_image(image):
    """OCR ì‹¤í–‰"""
    if image is None:
        print("âš ï¸ [ERROR] OCR ìˆ˜í–‰í•  ì´ë¯¸ì§€ê°€ Noneì…ë‹ˆë‹¤.")
        return None

    config = "--oem 3 --psm 3"
    text_tesseract = pytesseract.image_to_string(image, config=config, lang='kor+eng')

    ocr = PaddleOCR(lang="korean")
    result_paddle = ocr.ocr(image, cls=True)

    extracted_texts = []

    if result_paddle and result_paddle != [[]]:
        for line in result_paddle:
            for word in line:
                extracted_texts.append(word[1][0])

    extracted_text = text_tesseract.strip() + " " + " ".join(extracted_texts).strip()
    
    # ğŸ”¹ OCR ê²°ê³¼ ì¶œë ¥ ğŸ”¹
    print("ğŸ“Œ [DEBUG] OCR ì¶”ì¶œ í…ìŠ¤íŠ¸:", extracted_text.split())

    return extracted_text.split()

def parse_ocr_results(ocr_results):
    """OCR ê²°ê³¼ì—ì„œ ë‚ ì§œ, ë°°ë‹¬ ê±´ìˆ˜, ì´ë™ ê±°ë¦¬, ìˆ˜ìµ ì •ë³´ ì¶”ì¶œ"""
    date, delivery_count, distance, earnings = None, None, None, None
    month, day = None, None

    for text in ocr_results:
        if "ì›”" in text and len(text) <= 4:  # ex: "8ì›”"
            month = text.strip()
        elif "ì¼" in text and len(text) <= 4:  # ex: "28ì¼"
            day = text.strip()
        elif "/" in text:
            split_values = text.split("/")
            if len(split_values) == 2:
                delivery_count = split_values[0].strip().replace("ê±´", "")
                distance = split_values[1].strip()
        elif "ê±´" in text:
            delivery_count = text.replace("ê±´", "").strip()
        elif "km" in text:
            # ğŸ”¹ ê±°ë¦¬ê°’ì´ ì†Œìˆ˜ì  í¬í•¨ëœ ê²½ìš° ì œëŒ€ë¡œ ì¸ì‹ë˜ë„ë¡ ìˆ˜ì •
            if "." in text:
                distance = text.strip()
            elif distance is None:
                distance = text.strip()
        elif "ì›" in text:
            earnings = text.replace(",", "").strip()

    # ğŸ”¹ ë‚ ì§œ ì¡°í•©
    if month and day:
        date = f"{month} {day}"

    if earnings and earnings.isdigit():
        earnings = f"{int(earnings):,}ì›"

    return date, delivery_count, distance, earnings

def main(image_path):
    print("ğŸ” [INFO] íŠ¹ì • ìœ„ì¹˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

    image, edged = preprocess_image(image_path)
    if image is None:
        return

    cropped_image = detect_text_box(image, edged)
    if cropped_image is None:
        return

    resized = cv2.resize(cropped_image, (cropped_image.shape[1] * 2, cropped_image.shape[0] * 2))
    show_image("Resized Image for OCR", resized)

    ocr_results = extract_text_from_image(resized)
    if ocr_results is None:
        return

    date, delivery_count, distance, earnings = parse_ocr_results(ocr_results)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥ âœ…
    print("\nâœ… [FINAL RESULT]")
    print("ğŸ“Œ ë°°ë‹¬ì˜ ë¯¼ì¡±")
    print("ğŸ“… ë‚ ì§œ:", date)
    print("ğŸ“¦ ë°°ë‹¬ê±´ìˆ˜:", delivery_count)
    print("ğŸš´ ì´ë™ê±°ë¦¬:", distance)
    print("ğŸ’° ìˆ˜ìµ:", earnings)

if __name__ == "__main__":
    image_path = "C:\\DB\\images\\KakaoTalk_20220829_090207582_01.jpg"
    main(image_path)
