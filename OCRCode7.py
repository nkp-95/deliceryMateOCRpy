import cv2
import numpy as np
import pytesseract
from paddleocr import PaddleOCR

def show_image(title, image):
    """ë””ë²„ê¹…ìš© ì´ë¯¸ì§€ ì¶œë ¥ í•¨ìˆ˜"""
    cv2.imshow(title, image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: í‘ë°± ë³€í™˜, ëŒ€ë¹„ ì¡°ì •, ë…¸ì´ì¦ˆ ì œê±° ë“±"""
    
    # ì›ë³¸ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    image = cv2.imread(image_path)

    # 1. **í‘ë°± ë³€í™˜**
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # 2. **ë°ê¸° ë³´ì • ë° ëŒ€ë¹„ ê°•í™”**
    equalized = cv2.equalizeHist(gray)

    # 3. **Adaptive Thresholding ì ìš©** (ë¡œì»¬ ëŒ€ë¹„ ìµœì í™”)
    adaptive_thresh = cv2.adaptiveThreshold(equalized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                            cv2.THRESH_BINARY, 11, 2)

    # 4. **Sharpening (ì„ ëª…í™”) ì ìš©**
    kernel = np.array([[0, -1, 0],
                        [-1,  5, -1],
                        [0, -1, 0]])
    sharpened = cv2.filter2D(adaptive_thresh, -1, kernel)

    # 5. **ì—£ì§€ ê²€ì¶œ (Canny)**
    edged = cv2.Canny(sharpened, 50, 200)

    return image, edged

def detect_text_box(image, edged):
    """ì‚¬ê°í˜• ë°•ìŠ¤ ê²€ì¶œí•˜ì—¬ OCR ì˜ì—­ í¬ë¡­"""
    
    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    best_box = None
    max_area = 0

    for cnt in contours:
        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
        if len(approx) == 4:
            x, y, w, h = cv2.boundingRect(approx)
            aspect_ratio = w / float(h)

            # íŠ¹ì • ë¹„ìœ¨ê³¼ í¬ê¸°ë¥¼ ë§Œì¡±í•˜ëŠ” ê²½ìš° ì„ íƒ
            if 1.5 < aspect_ratio < 3 and w * h > 5000:  
                if w * h > max_area:
                    best_box = (x, y, w, h)
                    max_area = w * h

    if best_box:
        x, y, w, h = best_box

        # ğŸ”¹ í¬ë¡­ ì˜ì—­ ì¡°ì • (ìƒë‹¨ ë¶€ë¶„ í¬í•¨) ğŸ”¹
        y = max(0, y - int(h * 0.3))  # ìƒë‹¨ì„ 30% ë” í¬í•¨í•˜ë„ë¡ ì¡°ì •
        
        cropped = image[y:y+h, x:x+w]
        show_image("Cropped ROI", cropped)
        cv2.imwrite("cropped_output.jpg", cropped)
        print("âœ… [INFO] í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_output.jpg")
        return cropped
    else:
        print("âš ï¸ [ERROR] í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

def extract_text_from_image(image):
    """OCR ì‹¤í–‰"""
    
    config = "--oem 3 --psm 6"
    text_tesseract = pytesseract.image_to_string(image, config=config, lang='kor+eng')

    ocr = PaddleOCR(lang="korean")
    result_paddle = ocr.ocr(image, cls=True)

    extracted_texts = []
    
    if result_paddle and result_paddle != [[]]:
        for line in result_paddle:
            for word in line:
                extracted_texts.append(word[1][0])

    # ğŸ”¹ OCR ê²°ê³¼ ì¶œë ¥ ğŸ”¹
    print("ğŸ“Œ [DEBUG] OCR ì¶”ì¶œ í…ìŠ¤íŠ¸:", extracted_texts)

    return extracted_texts

def parse_ocr_results(ocr_results):
    """OCR ê²°ê³¼ì—ì„œ ë‚ ì§œ, ë°°ë‹¬ ê±´ìˆ˜, ì´ë™ ê±°ë¦¬, ìˆ˜ìµ ì •ë³´ ì¶”ì¶œ"""

    date, delivery_count, distance, earnings = None, None, None, None

    for text in ocr_results:
        if "ì›”" in text and "ì¼" in text:
            date = text.strip()
        elif "/" in text:  # ğŸ”¹ ë°°ë‹¬ ê±´ìˆ˜ì™€ ì´ë™ ê±°ë¦¬ êµ¬ë¶„ ğŸ”¹
            split_values = text.split("/")
            if len(split_values) == 2:
                delivery_count = split_values[0].strip()
                distance = split_values[1].strip()
        elif "ì›" in text:
            earnings = text.strip()

    return date, delivery_count, distance, earnings

def main(image_path):
    print("ğŸ” [INFO] íŠ¹ì • ìœ„ì¹˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

    image, edged = preprocess_image(image_path)

    cropped_image = detect_text_box(image, edged)
    if cropped_image is None:
        return None

    # í¬ë¡­ëœ ì´ë¯¸ì§€ í•´ìƒë„ ì¦ê°€ í›„ OCR ì‹¤í–‰
    resized = cv2.resize(cropped_image, (cropped_image.shape[1] * 2, cropped_image.shape[0] * 2))
    show_image("Resized Image for OCR", resized)

    print("âœ… [INFO] í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ë¡­ ì„±ê³µ. OCR ì ìš© ì¤‘...")
    ocr_results = extract_text_from_image(resized)

    # ğŸ”¹ OCR ê²°ê³¼ ë¶„ë¥˜ ğŸ”¹
    date, delivery_count, distance, earnings = parse_ocr_results(ocr_results)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥ âœ…
    print("\nâœ… [FINAL RESULT]")
    print("ğŸ“Œ ë°°ë‹¬ì˜ ë¯¼ì¡±")
    print("ğŸ“… ë‚ ì§œ:", date)
    print("ğŸ“¦ ë°°ë‹¬ê±´ìˆ˜:", delivery_count)
    print("ğŸ›µ ì´ë™ê±°ë¦¬:", distance)
    print("ğŸ’° ìˆ˜ìµ:", earnings)

if __name__ == "__main__":
    image_path = "C:\\DB\\images\\KakaoTalk_20220829_090207582_01.jpg"
    main(image_path)
